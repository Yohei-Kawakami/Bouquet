{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6011,
     "status": "ok",
     "timestamp": 1554727262326,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "jezcg3vK5zaH",
    "outputId": "b5d2fb13-d87c-46ac-b92a-43f4aaf4210c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
      "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
      "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1548288/45929032 bytes (3.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5136384/45929032 bytes (11.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8871936/45929032 bytes (19.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12607488/45929032 bytes (27.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16351232/45929032 bytes (35.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20078592/45929032 bytes (43.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23912448/45929032 bytes (52.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27729920/45929032 bytes (60.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31342592/45929032 bytes (68.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35053568/45929032 bytes (76.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38830080/45929032 bytes (84.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42557440/45929032 bytes (92.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
      "  Done\n",
      "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import collections as cl\n",
    "from copy import deepcopy\n",
    "import moviepy.editor as mpe\n",
    "\n",
    "\n",
    "class SynthesizeNetwork:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.video_path = \"test_video.mp4\"\n",
    "        self.category_path = \"model_data/0317_7model_1.h5\"\n",
    "        self.num_cut = 1 #フレーム間の数　１なら全フレーム取得する\n",
    "\n",
    "    def load_model(self, category_path=None):\n",
    "        #モデルのロードをするだけの関数\n",
    "        if not category_path:\n",
    "            category_path = self.category_path\n",
    "        self.category_model = models.load_model(category_path)\n",
    "\n",
    "\n",
    "    def movie_to_image(self, video_path=None, num_cut=None, size=(150, 150)):\n",
    "        #動画のパスを渡すとnum_cut(フレーム)ごとの画像をarrayにして返す\n",
    "\n",
    "        if not num_cut:\n",
    "            num_cut = self.num_cut\n",
    "        if not video_path:\n",
    "            video_path = self.video_path\n",
    "\n",
    "        video = []\n",
    "        #size = (150, 150)\n",
    "        frame_count = 0\n",
    "        # キャプチャ動画読み込み（キャプチャ構造体生成）\n",
    "        capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # フレーム画像がある限りループ\n",
    "        while(capture.isOpened()):\n",
    "            # フレーム画像一枚取得\n",
    "            ret, frame = capture.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "\n",
    "            # 指定した数だけフレーム画像を間引いて保存\n",
    "            if frame_count % num_cut == 0:\n",
    "                frame = cv2.resize(frame, size)\n",
    "                #print(frame.shape)\n",
    "                video.append(frame)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        # キャプチャ構造体開放\n",
    "        capture.release()\n",
    "        video_ar = np.array(video)\n",
    "\n",
    "        #配列が空ならエラーにする\n",
    "        if not np.any(video_ar):\n",
    "            raise Exception('配列が空です!')\n",
    "\n",
    "        return video_ar\n",
    "\n",
    "\n",
    "    def background_subtraction(self, video_ar):\n",
    "        #背景差分をとる関数\n",
    "        sub = video_ar[:-1] - video_ar[1:]\n",
    "        #maeの計算 shape(sample数-1,)\n",
    "        subtraction_ar = np.mean(np.abs(sub.reshape(len(sub), -1)), axis=1)\n",
    "        return subtraction_ar\n",
    "\n",
    "\n",
    "    def get_thresh_subtraction_index(self, subtraction_ar):\n",
    "        \"\"\"\n",
    "        背景差分を渡すと、シーン分割のインデックスを返す関数\n",
    "\n",
    "        scene_ar:array shape(num_scene, )\n",
    "            0から始まる。各値はシーンの開始フレーム, 動画の最終フレーム\n",
    "        \"\"\"\n",
    "\n",
    "        THRESH = 0.7 #差分の閾値\n",
    "\n",
    "        scene_ar = np.where(subtraction_ar >= THRESH)[0]\n",
    "        scene_ar += 1  #差分なのでシーンの分かれ目はプラス１になる\n",
    "        scene_ar = np.insert(scene_ar, 0, 0)  #ぜろを先頭に挿入\n",
    "\n",
    "        #秒数が近いインデックスは消す 閾値15フレーム\n",
    "        for i in range(len(scene_ar)):\n",
    "            try:\n",
    "                while True:\n",
    "                    if (scene_ar[i + 1] - scene_ar[i]) <= 15:\n",
    "                        scene_ar = np.delete(scene_ar, i + 1)\n",
    "                    else:\n",
    "                        break\n",
    "            except IndexError:\n",
    "                break\n",
    "\n",
    "        #動画の最後からフレームが空いてないとそのインデックスは消す\n",
    "        while True:\n",
    "            if (len(subtraction_ar) - scene_ar[-1]) <= 15:\n",
    "                scene_ar = np.delete(scene_ar, -1)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        scene_ar = np.append(scene_ar,len(subtraction_ar))  #動画の最終フレーム数を最後に挿入\n",
    "        return scene_ar\n",
    "\n",
    "\n",
    "    def get_choice_subtraction_index(self, subtraction_ar, num_scene):\n",
    "        \"\"\"\n",
    "        背景差分を渡すと、シーン分割のインデックスを返す関数\n",
    "\n",
    "        num_scene: int\n",
    "            シーンの分かれ目の欲しい数　2ならシーンとしては3になります\n",
    "        scene_ar:array shape(num_scene, )\n",
    "            0から始まる。各値はシーンの開始フレーム, 動画の最終フレーム\n",
    "        \"\"\"\n",
    "        thresh_frame = 90 #間を開けるフレーム数の閾値\n",
    "\n",
    "        #ゼロなら処理終了\n",
    "        if num_scene == 0:\n",
    "            scene_ar = np.array([0, len(subtraction_ar)])\n",
    "            return scene_ar\n",
    "\n",
    "        arg_ind = np.argsort(-subtraction_ar)\n",
    "        kari_num_scene = 10\n",
    "        #kari_num_sceneが希望する分割数より少ない場合増やす\n",
    "        if num_scene > kari_num_scene:\n",
    "            kari_num_scene = num_scene + 5\n",
    "\n",
    "        while len(arg_ind) >= kari_num_scene:\n",
    "            #とりあえず差分上位１０個だけ抜き出す,足りないならループで増やす\n",
    "            arg_kari_ind = arg_ind[:kari_num_scene]\n",
    "            sort_ind = np.sort(arg_kari_ind)\n",
    "\n",
    "            #秒数が近いインデックスは消す 閾値15フレーム\n",
    "            for i in range(len(sort_ind)):\n",
    "                try:\n",
    "                    while True:\n",
    "                        if (sort_ind[i + 1] - sort_ind[i]) <= thresh_frame:\n",
    "                            sort_ind = np.delete(sort_ind, i + 1)\n",
    "                        else:\n",
    "                            break\n",
    "                except IndexError:\n",
    "                    break\n",
    "\n",
    "            #動画の最初から0.5秒空いてないとそのインデックスは消す\n",
    "            try:\n",
    "                while True:\n",
    "                    if sort_ind[0] <= thresh_frame:\n",
    "                        sort_ind = np.delete(sort_ind, 0)\n",
    "                    else:\n",
    "                        break\n",
    "            \n",
    "            #動画の最後から0.5秒空いてないとそのインデックスは消す\n",
    "                while True:\n",
    "                    if (len(subtraction_ar) - 1 - sort_ind[-1]) <= thresh_frame:\n",
    "                        sort_ind = np.delete(sort_ind, -1)\n",
    "                    else:\n",
    "                        break\n",
    "            except IndexError:\n",
    "                    break\n",
    "\n",
    "            #num_sceneより多くシーンが抜き出せていればbreakする\n",
    "            if len(sort_ind) >= num_scene:\n",
    "                break\n",
    "            else:\n",
    "                kari_num_scene += 5\n",
    "\n",
    "        #昇順になっているsort_indを差分降順に直す\n",
    "        scene_ar = np.zeros(len(arg_kari_ind)) - 99\n",
    "        for i in sort_ind:\n",
    "            id = np.where(arg_kari_ind == i)[0]\n",
    "            scene_ar[id] = i\n",
    "        scene_ar = np.delete(scene_ar, np.where(scene_ar == -99))\n",
    "        scene_ar += 1  #差分なのでシーンの分かれ目はプラス１になる\n",
    "        scene_ar = np.sort(scene_ar[:num_scene])  #シーンを取り出し後昇順に並び替える\n",
    "        scene_ar = np.insert(scene_ar, 0, 0)  #ぜろを先頭に挿入\n",
    "        scene_ar = np.append(scene_ar,len(subtraction_ar))  #動画の最終フレーム数を最後に挿入\n",
    "\n",
    "        return scene_ar\n",
    "\n",
    "    def classify_movie_to_json(self, image_ar, scene_ar, video_path=None, json_name=None):\n",
    "        \"\"\"\n",
    "        素材一覧のjsonファイルを作る\n",
    "        \"\"\"\n",
    "        if not json_name:\n",
    "            json_name = \"material\" #jsonファイルの名前\n",
    "\n",
    "        if not video_path:\n",
    "            video_path = self.video_path  #編集したい動画のパス\n",
    "        print(\"try前\")\n",
    "        try:\n",
    "            f = open(json_name + \".json\", 'r')\n",
    "            json_data = json.load(f)\n",
    "            jsn = cl.OrderedDict(json_data)\n",
    "            num_count = max(list(map(int, jsn.keys()))) + 1\n",
    "\n",
    "        except:\n",
    "            #collections.OrderedDictで順序を指定した辞書を作成\n",
    "            jsn = cl.OrderedDict()\n",
    "            num_count = 0\n",
    "        print(\"try後\")\n",
    "\n",
    "        image_ar = image_ar / 255.\n",
    "        print(image_ar.shape)\n",
    "        pred_proba = self.category_model.predict(image_ar, verbose=1)\n",
    "        print(\"pred完了\")\n",
    "\n",
    "        for i in range(len(scene_ar)-1):\n",
    "            arange_ar = np.arange(scene_ar[i], scene_ar[i + 1]).astype(\"int32\")\n",
    "            clas = np.argmax(np.sum(pred_proba[arange_ar, :], axis=0))\n",
    "            pred_proba_one_class = pred_proba[arange_ar, clas].reshape(-1).tolist()\n",
    "            #辞書の作成\n",
    "            data = cl.OrderedDict()\n",
    "            data[\"path\"] = video_path\n",
    "            data[\"start\"] = int(scene_ar[i])\n",
    "            data[\"stop\"] = int(scene_ar[i + 1])\n",
    "            data[\"class\"] = int(clas)\n",
    "            data[\"classs_proba\"] = pred_proba_one_class\n",
    "            jsn[num_count] = data\n",
    "            num_count += 1\n",
    "            print(str(i) + \"シーン目　素材分類完了\")\n",
    "\n",
    "        #json.dump関数でファイルに書き込む 二回やらないとなぜかうまく書き込めない\n",
    "        fw = open(json_name + \".json\", 'w')\n",
    "        json.dump(jsn, fw, indent=4)\n",
    "        fw = open(json_name + \".json\", 'w')\n",
    "        json.dump(jsn, fw, indent=4)\n",
    "        print(\"json書き出し完了：\")\n",
    "\n",
    "\n",
    "    def init_material_json(self):\n",
    "        json_name = \"material\"\n",
    "        fw = open(json_name + \".json\", 'w')\n",
    "        json.dump(\"\", fw, indent=4)\n",
    "        fw = open(json_name + \".json\", 'w')\n",
    "        json.dump(\"\", fw, indent=4)\n",
    "        print(\"json初期化完了：\")\n",
    "\n",
    "    def get_num_scene(self, video_path):\n",
    "        \"\"\"\n",
    "        動画から取り出すシーン数を決める\n",
    "        \"\"\"\n",
    "        image_ar = self.movie_to_image(video_path)\n",
    "        video_span = image_ar.shape[0]/30\n",
    "\n",
    "        if (video_span//9) -1 < 1:\n",
    "            num_scene = 0\n",
    "        elif 1 <= (video_span//9) -1 < 19:\n",
    "            num_scene = (video_span//9) -1\n",
    "\n",
    "        else:\n",
    "            num_scene = 19\n",
    "        return num_scene\n",
    "\n",
    "\n",
    "    def get_scene_movie_json(self,video_path):\n",
    "        \"\"\"\n",
    "        動画をシーンで分類しジェイソンファイルを作成するまでまとめたやつ\n",
    "        \"\"\"\n",
    "        image_ar = self.movie_to_image(video_path)\n",
    "        num_scene = self.get_num_scene(video_path)\n",
    "        print(\"ビデオをイメージ化済み\")\n",
    "        sabun_ar = self.background_subtraction(image_ar)\n",
    "        scene_ar = self.get_choice_subtraction_index(sabun_ar, int(num_scene))\n",
    "        print(\"分類開始\")\n",
    "        #self.scene_to_movie(scene_ar, video_path)\n",
    "        self.classify_movie_to_json(image_ar, scene_ar, video_path)\n",
    "        \n",
    "\n",
    "\n",
    "    def synthesizer(self, material_json, map_file=None):\n",
    "        \"\"\"\n",
    "        動画合成\n",
    "        mapfileをどうするか\n",
    "        \"\"\"\n",
    "\n",
    "        #今後map_classとmap_secondはファイルを用意して読み込む形にする\n",
    "        map_class = [1, 1, 1, 0, 1, 2, 1, 1, 1, 5, 0, 5, 0, 0, 0, 5, 1, 1, 1, 1]\n",
    "        map_second = [0.,0.86666667,2.8,6.56666667,9.76666667,12.16666667,\n",
    "                    12.83333333, 16.66666667, 17.2,        22.1,        24.73333333, 26.96666667,\n",
    "                    27.6,        29.8,        41.23333333, 43.16666667, 46.66666667, 51.23333333,\n",
    "                    52.86666667, 57.76666667, 59.96666667]\n",
    "\n",
    "        num_map = len(map_class)\n",
    "        fw = open(material_json, 'r')\n",
    "        material = json.load(fw) #辞書\n",
    "        material_class = np.array([material[k][\"class\"] for k in material.keys()]) #数字のarray\n",
    "        material_length_frame = np.array(\n",
    "            [len(material[k][\"classs_proba\"]) for k in material.keys()])  #動画ごとのフレーム数\n",
    "\n",
    "        Exclusion_ind_list = []\n",
    "        export_ar = np.empty((0,3))\n",
    "\n",
    "        for i in range(num_map):\n",
    "            kaburimode = False\n",
    "            material_del = deepcopy(material)\n",
    "            print(material_del.keys())\n",
    "            for d in Exclusion_ind_list:\n",
    "                print(d)\n",
    "                try:\n",
    "                    del material_del[str(int(d))]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            material_class_del = np.array([\n",
    "                material_del[k][\"class\"] for k in material_del.keys()])  #数字のarray\n",
    "            material_length_frame_del = np.array([\n",
    "                len(material_del[k][\"classs_proba\"]) for k in material_del.keys()]) #動画ごとのフレーム数\n",
    "\n",
    "            map_num_frame = int((map_second[i + 1] - map_second[i])*30)\n",
    "            c_ind = np.where(material_class_del == map_class[i])[0]  #クラスがあるか\n",
    "            l_ind = np.where(material_length_frame_del > map_num_frame)[0]  #長さが足りているか\n",
    "\n",
    "            if not np.any(l_ind):  #ないなら被りおk状態になる\n",
    "                print(\"被りありモード\")\n",
    "                kaburimode = True\n",
    "                c_ind = np.where(material_class == map_class[i])[0]\n",
    "                l_ind = np.where(material_length_frame > map_num_frame)[0]\n",
    "            print(map_num_frame)\n",
    "            ##ここから合致した動画を探す\n",
    "            if not np.any(l_ind):\n",
    "                print(\"素材の長さが足りないです　処理終了\")\n",
    "                break\n",
    "\n",
    "            if not np.any(c_ind):\n",
    "                if int(map_class[i]) in [2, 3, 4, 5, 6]:  #if ブツ撮り\n",
    "                    print(\"ブツ撮りのその他のクラスへ割り当て\")\n",
    "                    if kaburimode:\n",
    "                        c_ind = np.where(material_class >= 2)[0]\n",
    "                    else:\n",
    "                        c_ind = np.where(material_class_del >= 2)[0]\n",
    "\n",
    "            if not np.any(c_ind):\n",
    "                print(\"クラスなし適当に割り当て\")\n",
    "                c_ind = l_ind\n",
    "\n",
    "            if np.any(c_ind) and np.any(l_ind):\n",
    "                find_list = []\n",
    "                for c in c_ind:\n",
    "                    if c in l_ind:\n",
    "                        find_list += [c]\n",
    "                find_ar = np.array(find_list)\n",
    "\n",
    "            if not np.any(find_ar):\n",
    "                print(\"find_arなし適当に割り当て\")\n",
    "                find_ar = l_ind\n",
    "\n",
    "            if kaburimode:\n",
    "                sort_ind = np.argsort(material_length_frame)\n",
    "            else:\n",
    "                sort_ind = np.argsort(material_length_frame_del)\n",
    "\n",
    "            optimum_ar = np.empty((0,2))\n",
    "            for j in find_ar:\n",
    "                for l, k in enumerate(sort_ind):\n",
    "                    if j == k:\n",
    "                        optimum_ar =np.vstack((optimum_ar, np.array([l, k])))\n",
    "                        break\n",
    "            optimum_ind = optimum_ar[np.argmin(optimum_ar[:, 0]), 1]\n",
    "\n",
    "            if kaburimode:\n",
    "                optimum_ind = str(int(optimum_ind))\n",
    "            else:\n",
    "                optimum_ind = list(material_del.keys())[int(optimum_ind)]\n",
    "\n",
    "            ##ここから最適なフレームを抜き出す\n",
    "            class_proba_ar = np.array(material[optimum_ind][\"classs_proba\"])\n",
    "            print(len(class_proba_ar))\n",
    "            print(\"map_num_frame\")\n",
    "            print(map_num_frame)\n",
    "            ind_ar = np.array([np.arange(i, i + map_num_frame) for i in np.arange(0, len(class_proba_ar) - map_num_frame)])  #最後オーバーすると怖いので一応マイナス１\n",
    "            start = (np.argmax(np.sum(class_proba_ar[ind_ar], axis=1))\n",
    "                    + material[optimum_ind][\"start\"]) / 30  #一番確率が高いシーケンスの始まり秒\n",
    "            end = start + map_second[i + 1] - map_second[i]\n",
    "            #arrayに保存しておく\n",
    "            export_ar = np.vstack((export_ar, np.array([optimum_ind, start, end]).reshape(1, 3)))\n",
    "            #使用ずみの素材は除くためのリスト\n",
    "            Exclusion_ind_list += [optimum_ind]\n",
    "\n",
    "        #書き出し\n",
    "        cliplist = []\n",
    "        for i in range(len(export_ar)):\n",
    "            print(i)\n",
    "            cliplist += [\n",
    "                VideoFileClip(\n",
    "                    material[str(export_ar[i, 0])][\"path\"],\n",
    "                    audio=False).subclip(\n",
    "                        float(export_ar[i, 1]), float(export_ar[i, 2]))\n",
    "            ]\n",
    "        final_clip = concatenate_videoclips(cliplist)  #ビデオの接続\n",
    "        audioclip = AudioFileClip(\"kzk_wedding1.mp3\")\n",
    "        final_clip = final_clip.set_audio(audioclip)\n",
    "        final_clip.write_videofile(\"a_test_mv.mp4\", fps=29)  # Many options...#書き込み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45341,
     "status": "ok",
     "timestamp": 1554727253124,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "SEUsrBPCAn4E",
    "outputId": "aad2fe95-2776-4f12-9bdd-08f497b44294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20891,
     "status": "ok",
     "timestamp": 1554727253126,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "rgm2yv-ZAvbb",
    "outputId": "2216c276-0f0b-4e20-c8d2-304c0cf5c6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/wedding_test\n"
     ]
    }
   ],
   "source": [
    "# !pwd\n",
    "# !ls\n",
    "cd /content/gdrive/My Drive/wedding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZdQCqhM8r6a"
   },
   "outputs": [],
   "source": [
    "# video_paths = [\"C0056.MP4\",\"C0058.MP4\",\"C0059.MP4\",\"C0060.MP4\",\"C0061.MP4\",\"C0063.MP4\",\"C0064.MP4\",\"C0065.MP4\",\"C0066.MP4\",\"C0067.MP4\",\"C0068.MP4\"]\n",
    "\n",
    "# # 書き出し\n",
    "# cliplist = []\n",
    "\n",
    "# cliplist += [VideoFileClip(path,audio=False) for path in video_paths]\n",
    "\n",
    "# final_clip_s = concatenate_videoclips(cliplist)  #ビデオの接続\n",
    "# # final_clip.write_videofile(\"combine_movie.mp4\", fps=29)  # Many options...#書き込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_cKjvGsH3NA"
   },
   "outputs": [],
   "source": [
    "# import moviepy.video.fx.all\n",
    "\n",
    "# final_clip = moviepy.video.fx.all.resize(final_clip_s, height=150, width=150)\n",
    "# final_clip = final_clip.iter_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJAwhnkOybdR"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# final_clip_list = np.zeros([1800, 150, 266, 3])\n",
    "# for i, clip in enumerate(final_clip):\n",
    "#   if i < 1800:\n",
    "#     final_clip_list[i] = clip\n",
    "    \n",
    "#   else:\n",
    "#     break\n",
    "  \n",
    "# #   final_clip_list.append(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1554011262061,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "JfeQWgKXRcLp",
    "outputId": "f13b5f3e-70eb-4001-c7f8-0849e1059884"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # for i in range(5):\n",
    "# #   final_clip_list.append(i)\n",
    "\n",
    "# final_clip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-9OwhwvAynx"
   },
   "outputs": [],
   "source": [
    "# import SynthesizeNetwork\n",
    "wed = SynthesizeNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9gbHa5EikbD"
   },
   "source": [
    "# Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1554727269560,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "P9qC-YeeH3uW",
    "outputId": "5810d44f-b070-46b2-d1a6-e4b2071bb223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json初期化完了：\n"
     ]
    }
   ],
   "source": [
    "wed.init_material_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33201,
     "status": "ok",
     "timestamp": 1554727305051,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "LbukHkXyCKsg",
    "outputId": "dde5dde1-17b9-4ee9-d509-b86371b967be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "wed.load_model(\"0317_7model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LP4roAjB_0ma"
   },
   "outputs": [],
   "source": [
    "# video_path = \"combine_movie.mp4\"\n",
    "\n",
    "# wed.get_scene_movie_json(final_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 182078,
     "status": "ok",
     "timestamp": 1554727462320,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "7KvOrcWV6aiX",
    "outputId": "5ae62bec-9db4-4573-8fc2-45d00b25766d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ビデオをイメージ化済み\n",
      "分類開始\n",
      "try前\n",
      "try後\n",
      "(4590, 150, 150, 3)\n",
      "4590/4590 [==============================] - 29s 6ms/step\n",
      "pred完了\n",
      "0シーン目　素材分類完了\n",
      "1シーン目　素材分類完了\n",
      "2シーン目　素材分類完了\n",
      "3シーン目　素材分類完了\n",
      "4シーン目　素材分類完了\n",
      "5シーン目　素材分類完了\n",
      "6シーン目　素材分類完了\n",
      "7シーン目　素材分類完了\n",
      "8シーン目　素材分類完了\n",
      "9シーン目　素材分類完了\n",
      "10シーン目　素材分類完了\n",
      "11シーン目　素材分類完了\n",
      "12シーン目　素材分類完了\n",
      "13シーン目　素材分類完了\n",
      "14シーン目　素材分類完了\n",
      "15シーン目　素材分類完了\n",
      "16シーン目　素材分類完了\n",
      "json書き出し完了：\n"
     ]
    }
   ],
   "source": [
    "video_paths = [\"M&Y,Opening,vol1.MP4\"]\n",
    "\n",
    "for path in video_paths:\n",
    "  wed.get_scene_movie_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cugWHa8hA3g7"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# video_paths = [\"kzk_wedding8.mp4\"]\n",
    "# video_paths = [\"kzk_wedding1.mp4\",\"kzk_wedding2.mp4\",\"kzk_wedding3.mp4\",\"kzk_wedding4.mp4\",\"kzk_wedding5.mp4\",\"kzk_wedding6.mp4\",\"kzk_wedding7.mp4\", \"kzk_wedding8.mp4\", \"kzk_wedding9.mp4\"]\n",
    "\n",
    "for i in range(52):\n",
    "  try:\n",
    "    wed.get_scene_movie_json(\"cut{}.mp4\".format(i))\n",
    "  except:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrXi0CrbA3kD"
   },
   "outputs": [],
   "source": [
    "jsonpath = \"material.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5644
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 454427,
     "status": "ok",
     "timestamp": 1554727741259,
     "user": {
      "displayName": "Yohei Kawakami",
      "photoUrl": "https://lh6.googleusercontent.com/-mVGSw0CthvA/AAAAAAAAAAI/AAAAAAAAAXg/SdMQ2qjLEc0/s64/photo.jpg",
      "userId": "16594791006392015223"
     },
     "user_tz": -540
    },
    "id": "rN5JuwLjA3qV",
    "outputId": "6a50713b-6393-4cdb-b9db-852f896dc97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "26\n",
      "111\n",
      "map_num_frame\n",
      "26\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "57\n",
      "119\n",
      "map_num_frame\n",
      "57\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "113\n",
      "140\n",
      "map_num_frame\n",
      "113\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "95\n",
      "108\n",
      "map_num_frame\n",
      "95\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "72\n",
      "300\n",
      "map_num_frame\n",
      "72\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "19\n",
      "ブツ撮りのその他のクラスへ割り当て\n",
      "232\n",
      "map_num_frame\n",
      "19\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "115\n",
      "319\n",
      "map_num_frame\n",
      "115\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "15\n",
      "327\n",
      "map_num_frame\n",
      "15\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "147\n",
      "583\n",
      "map_num_frame\n",
      "147\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "78\n",
      "ブツ撮りのその他のクラスへ割り当て\n",
      "454\n",
      "map_num_frame\n",
      "78\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "67\n",
      "93\n",
      "map_num_frame\n",
      "67\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "18\n",
      "ブツ撮りのその他のクラスへ割り当て\n",
      "クラスなし適当に割り当て\n",
      "140\n",
      "map_num_frame\n",
      "18\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "65\n",
      "181\n",
      "map_num_frame\n",
      "65\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "11\n",
      "被りありモード\n",
      "342\n",
      "find_arなし適当に割り当て\n",
      "454\n",
      "map_num_frame\n",
      "342\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "11\n",
      "16\n",
      "58\n",
      "214\n",
      "map_num_frame\n",
      "58\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "11\n",
      "16\n",
      "9\n",
      "105\n",
      "ブツ撮りのその他のクラスへ割り当て\n",
      "クラスなし適当に割り当て\n",
      "256\n",
      "map_num_frame\n",
      "105\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "11\n",
      "16\n",
      "9\n",
      "4\n",
      "136\n",
      "クラスなし適当に割り当て\n",
      "323\n",
      "map_num_frame\n",
      "136\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "11\n",
      "16\n",
      "9\n",
      "4\n",
      "12\n",
      "被りありモード\n",
      "49\n",
      "111\n",
      "map_num_frame\n",
      "49\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "11\n",
      "16\n",
      "9\n",
      "4\n",
      "12\n",
      "14\n",
      "被りありモード\n",
      "146\n",
      "300\n",
      "map_num_frame\n",
      "146\n",
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'])\n",
      "14\n",
      "6\n",
      "3\n",
      "7\n",
      "13\n",
      "0\n",
      "15\n",
      "5\n",
      "1\n",
      "16\n",
      "8\n",
      "10\n",
      "11\n",
      "16\n",
      "9\n",
      "4\n",
      "12\n",
      "14\n",
      "13\n",
      "被りありモード\n",
      "66\n",
      "111\n",
      "map_num_frame\n",
      "66\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "[MoviePy] >>>> Building video a_test_mv.mp4\n",
      "[MoviePy] Writing audio in a_test_mvTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1326/1326 [00:01<00:00, 666.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] Writing video a_test_mv.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1740/1740 [04:05<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: a_test_mv.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wed.synthesizer(jsonpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjU6345dA3s9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wedding summary.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
